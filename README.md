[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_CN.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [æ—¥æœ¬èª](README_JP.md)

# ğŸ™ï¸ PersonaPlex

[![Docker](https://img.shields.io/badge/Docker-neosun%2Fpersonaplex-blue?logo=docker)](https://hub.docker.com/r/neosun/personaplex)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE-MIT)
[![Paper](https://img.shields.io/badge/ğŸ“„-Paper-blue)](https://arxiv.org/abs/2602.06053)
[![Model](https://img.shields.io/badge/ğŸ¤—-Model-yellow)](https://huggingface.co/nvidia/personaplex-7b-v1)
[![Demo](https://img.shields.io/badge/ğŸ®-Demo-green)](https://research.nvidia.com/labs/adlr/personaplex/)

**Real-time Full-Duplex Conversational AI with Voice and Role Control**

PersonaPlex is a speech-to-speech conversational model that enables persona control through text-based role prompts and audio-based voice conditioning. It produces natural, low-latency spoken interactions with consistent personas.

![Screenshot](assets/architecture_diagram.png)

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¯ **Full-Duplex** | Real-time bidirectional conversation |
| ğŸ­ **Persona Control** | Text prompts define AI personality |
| ğŸ—£ï¸ **Voice Selection** | 18 pre-trained voice options |
| ğŸŒ **Multi-language UI** | English, ä¸­æ–‡, ç¹é«”, æ—¥æœ¬èª |
| ğŸ³ **All-in-One Docker** | Single container deployment |
| ğŸ“¡ **REST API** | OpenAPI/Swagger documented |
| ğŸ”Œ **MCP Support** | Model Context Protocol integration |
| ğŸ–¥ï¸ **GPU Management** | Auto-select & memory offload |

## ğŸš€ Quick Start

### Docker (Recommended)

```bash
# Pull and run
docker run -d --gpus all \
  -p 8998:8998 \
  -e HF_TOKEN=your_token \
  --name personaplex \
  neosun/personaplex:latest

# Access Web UI
open http://localhost:8998
```

### Docker Compose

```yaml
version: '3.8'
services:
  personaplex:
    image: neosun/personaplex:latest
    container_name: personaplex
    ports:
      - "8998:8998"
    environment:
      - HF_TOKEN=${HF_TOKEN}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - /tmp/personaplex:/tmp/personaplex
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
```

```bash
# Set token and start
export HF_TOKEN=your_huggingface_token
docker-compose up -d
```

### One-Click Start

```bash
# Clone repository
git clone https://github.com/neosun100/personaplex.git
cd personaplex

# Set HF token
export HF_TOKEN=your_huggingface_token

# Start (auto-selects GPU with lowest memory usage)
./start.sh
```

## âš™ï¸ Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `HF_TOKEN` | - | **Required**: HuggingFace token |
| `PORT` | `8998` | Web UI port |
| `DEVICE` | `cuda` | Device: cuda, cpu |
| `CPU_OFFLOAD` | `false` | Offload to CPU if GPU OOM |
| `GPU_IDLE_TIMEOUT` | `300` | Auto-unload after idle (seconds) |
| `NVIDIA_VISIBLE_DEVICES` | `0` | GPU ID to use |

### GPU Selection

```bash
# Use specific GPU
export NVIDIA_VISIBLE_DEVICES=2
docker-compose up -d

# Or in docker-compose.yml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          device_ids: ['2']
          capabilities: [gpu]
```

## ğŸ—£ï¸ Voice Options

| Category | IDs | Description |
|----------|-----|-------------|
| Natural Female | NATF0-3 | Natural, conversational |
| Natural Male | NATM0-3 | Natural, conversational |
| Variety Female | VARF0-4 | Diverse styles |
| Variety Male | VARM0-4 | Diverse styles |

## ğŸ“ Prompt Examples

### Assistant (Default)
```
You are a wise and friendly teacher. Answer questions or provide advice in a clear and engaging way.
```

### Customer Service
```
You work for First Neuron Bank which is a bank and your name is Alexis Kim. Information: The customer's transaction for $1,200 at Home Depot was declined. Verify customer identity.
```

### Casual Conversation
```
You enjoy having a good conversation.
```

## ğŸ“¡ API Reference

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web UI |
| `/health` | GET | Health check |
| `/docs` | GET | Swagger API docs |
| `/api/gpu/status` | GET | GPU status |
| `/api/gpu/offload` | POST | Release GPU memory |
| `/api/voices` | GET | List voices |
| `/api/offline` | POST | Offline inference |
| `/api/chat` | WebSocket | Real-time conversation |

### Offline Inference

```bash
curl -X POST http://localhost:8998/api/offline \
  -F "file=@input.wav" \
  -F "voice_prompt=NATF2.pt" \
  -F "text_prompt=You are a helpful assistant." \
  -o output.wav
```

## ğŸ”Œ MCP Integration

See [MCP_GUIDE.md](MCP_GUIDE.md) for Model Context Protocol integration.

```json
{
  "mcpServers": {
    "personaplex": {
      "command": "docker",
      "args": ["exec", "-i", "personaplex", "python", "-m", "app.mcp_server"]
    }
  }
}
```

## ğŸ—ï¸ Project Structure

```
personaplex/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ server.py          # FastAPI server
â”‚   â”œâ”€â”€ mcp_server.py      # MCP server
â”‚   â””â”€â”€ templates/         # Web UI
â”œâ”€â”€ moshi/                  # Core model package
â”œâ”€â”€ client/                 # Original React client
â”œâ”€â”€ assets/                 # Test files
â”œâ”€â”€ Dockerfile             # All-in-One image
â”œâ”€â”€ docker-compose.yml     # Compose config
â”œâ”€â”€ start.sh               # One-click start
â””â”€â”€ MCP_GUIDE.md           # MCP documentation
```

## ğŸ› ï¸ Tech Stack

- **Model**: [PersonaPlex](https://huggingface.co/nvidia/personaplex-7b-v1) based on Moshi
- **Backend**: FastAPI + Uvicorn
- **Frontend**: Jinja2 + Vanilla JS
- **Container**: NVIDIA CUDA 12.4 + cuDNN
- **Protocol**: WebSocket + REST + MCP

## ğŸ“‹ Changelog

### v1.0.0 (2026-02-16)
- ğŸ³ All-in-One Docker deployment
- ğŸŒ Multi-language Web UI (EN/ä¸­æ–‡/ç¹é«”/æ—¥æœ¬èª)
- ğŸ“¡ REST API with Swagger docs
- ğŸ”Œ MCP server integration
- ğŸ–¥ï¸ Auto GPU selection
- ğŸ—‘ï¸ GPU memory offload

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing`)
5. Open a Pull Request

## ğŸ“„ License

- Code: MIT License
- Model Weights: [NVIDIA Open Model License](https://huggingface.co/nvidia/personaplex-7b-v1)

## ğŸ™ Acknowledgments

- [NVIDIA PersonaPlex](https://arxiv.org/abs/2602.06053) - Original research
- [Kyutai Moshi](https://arxiv.org/abs/2410.00037) - Base architecture
- [Helium LLM](https://kyutai.org/blog/2025-04-30-helium) - Language model backbone

---

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=neosun100/personaplex&type=Date)](https://star-history.com/#neosun100/personaplex)

## ğŸ“± Follow Us

![WeChat](https://img.aws.xin/uPic/æ‰«ç _æœç´¢è”åˆä¼ æ’­æ ·å¼-æ ‡å‡†è‰²ç‰ˆ.png)
